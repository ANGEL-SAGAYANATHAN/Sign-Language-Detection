# Sign Language Recognition App 

This project uses the machine learning models to develop a mobile application for sign language recognition. This application allows users to record videos of themselves using sign language movements, and it will then analyze those films to identify the appropriate signs. 

# Overview

This Flutter application recognizes sign language using machine learning models. Using the camera on their device, users can record videos of themselves using sign language movements. The software will then analyze the footage to identify the sigs the users are making. With the app's real-time feedback on recognized signs, users can improve their sign language skills or efficiently converse with hearing-impaired peoples.

![Screenshot 2024-04-04 100044](https://github.com/ANGEL-SAGAYANATHAN/Sign-Language-Detection/assets/156065480/f1ed4fde-b30a-4071-a234-cac088e29ad2)

# Features
1. Make movies of sign language movements with the camera on the device.
2. Use machine learning models to analyze sign language videos and identify the signs that are being done.
3. Present results in real time that show the identified signs.
4. Translate or describe signs that are identified to help users learn sign language.

# Installation
1. Clone this repository:`git clone https://github.com/ANGEL-SAGAYANATHAN/Sign-Language-Detection.git`
2. Open the project directory: `cd Sign-Language-Detection`
3. Update dependencies: `flutter pub get`

# Output Screenshot 
![Screenshot 2024-04-04 100016](https://github.com/ANGEL-SAGAYANATHAN/Sign-Language-Detection/assets/156065480/4df18d5f-a61f-4da6-bdcb-7ccaaa0ea8d6)


